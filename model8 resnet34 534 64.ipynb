{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict multi-mode with confidence: As written in evaluation metric page, we can predict 3 modes of motion trajectory.\n",
    "#Training loss with competition evaluation metric\n",
    "#Use Training abstraction library pytorch-ignite and pytorch-pfn-extras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/lyft/l5kit/blob/20ab033c01610d711c3d36e1963ecec86e8b85b6/l5kit/l5kit/evaluation/csv_utils.py#L140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/lyft/l5kit/blob/master/competition.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning:\n",
      "\n",
      "Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# --- plotly ---\n",
    "from plotly import tools, subplots\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "\n",
    "# --- models ---\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "# --- setup ---\n",
    "pd.set_option('max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "import pytorch_pfn_extras as ppe\n",
    "from math import ceil\n",
    "from pytorch_pfn_extras.training import IgniteExtensionsManager\n",
    "from pytorch_pfn_extras.training.triggers import MinValueTrigger\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "import pytorch_pfn_extras.training.extensions as E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dataset utils ---\n",
    "from typing import Callable\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "\n",
    "class TransformDataset(Dataset):\n",
    "    def __init__(self, dataset: Dataset, transform: Callable):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch = self.dataset[index]\n",
    "        return self.transform(batch)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l5kit version: 1.1.0\n"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "\n",
    "import l5kit\n",
    "from l5kit.data import ChunkedDataset, LocalDataManager\n",
    "from l5kit.dataset import EgoDataset, AgentDataset\n",
    "\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.visualization import draw_trajectory, TARGET_POINTS_COLOR\n",
    "from l5kit.geometry import transform_points\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from l5kit.data import PERCEPTION_LABELS\n",
    "from prettytable import PrettyTable\n",
    "from l5kit.evaluation import write_pred_csv\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "rc('animation', html='jshtml')\n",
    "print(\"l5kit version:\", l5kit.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function\n",
    "#To define loss function to calculate competition evaluation metric in batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function utils ---\n",
    "# Original code from https://github.com/lyft/l5kit/blob/20ab033c01610d711c3d36e1963ecec86e8b85b6/l5kit/l5kit/evaluation/metrics.py\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def pytorch_neg_multi_log_likelihood_batch(\n",
    "    gt: Tensor, pred: Tensor, confidences: Tensor, avails: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "    Compute a negative log-likelihood for the multi-modal scenario.\n",
    "    log-sum-exp trick is used here to avoid underflow and overflow, For more information about it see:\n",
    "    https://en.wikipedia.org/wiki/LogSumExp#log-sum-exp_trick_for_log-domain_calculations\n",
    "    https://timvieira.github.io/blog/post/2014/02/11/exp-normalize-trick/\n",
    "    https://leimao.github.io/blog/LogSumExp/\n",
    "    Args:\n",
    "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        pred (Tensor): array of shape (bs)x(modes)x(time)x(2D coords)\n",
    "        confidences (Tensor): array of shape (bs)x(modes) with a confidence for each mode in each sample\n",
    "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
    "    Returns:\n",
    "        Tensor: negative log-likelihood for this example, a single float number\n",
    "    \"\"\"\n",
    "    assert len(pred.shape) == 4, f\"expected 3D (MxTxC) array for pred, got {pred.shape}\"\n",
    "    batch_size, num_modes, future_len, num_coords = pred.shape\n",
    "\n",
    "    assert gt.shape == (batch_size, future_len, num_coords), f\"expected 2D (Time x Coords) array for gt, got {gt.shape}\"\n",
    "    assert confidences.shape == (batch_size, num_modes), f\"expected 1D (Modes) array for gt, got {confidences.shape}\"\n",
    "    assert torch.allclose(torch.sum(confidences, dim=1), confidences.new_ones((batch_size,))), \"confidences should sum to 1\"\n",
    "    assert avails.shape == (batch_size, future_len), f\"expected 1D (Time) array for gt, got {avails.shape}\"\n",
    "    # assert all data are valid\n",
    "    assert torch.isfinite(pred).all(), \"invalid value found in pred\"\n",
    "    assert torch.isfinite(gt).all(), \"invalid value found in gt\"\n",
    "    assert torch.isfinite(confidences).all(), \"invalid value found in confidences\"\n",
    "    assert torch.isfinite(avails).all(), \"invalid value found in avails\"\n",
    "\n",
    "    # convert to (batch_size, num_modes, future_len, num_coords)\n",
    "    gt = torch.unsqueeze(gt, 1)  # add modes\n",
    "    avails = avails[:, None, :, None]  # add modes and cords\n",
    "\n",
    "    # error (batch_size, num_modes, future_len)\n",
    "    error = torch.sum(((gt - pred) * avails) ** 2, dim=-1)  # reduce coords and use availability\n",
    "\n",
    "    with np.errstate(divide=\"ignore\"):  # when confidence is 0 log goes to -inf, but we're fine with it\n",
    "        # error (batch_size, num_modes)\n",
    "        error = torch.log(confidences) - 0.5 * torch.sum(error, dim=-1)  # reduce time\n",
    "\n",
    "    # use max aggregator on modes for numerical stability\n",
    "    # error (batch_size, num_modes)\n",
    "    max_value, _ = error.max(dim=1, keepdim=True)  # error are negative at this point, so max() gives the minimum one\n",
    "    error = -torch.log(torch.sum(torch.exp(error - max_value), dim=-1, keepdim=True)) - max_value  # reduce modes\n",
    "    # print(\"error\", error)\n",
    "    return torch.mean(error)\n",
    "\n",
    "\n",
    "def pytorch_neg_multi_log_likelihood_single(\n",
    "    gt: Tensor, pred: Tensor, avails: Tensor\n",
    ") -> Tensor:\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        gt (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        pred (Tensor): array of shape (bs)x(time)x(2D coords)\n",
    "        avails (Tensor): array of shape (bs)x(time) with the availability for each gt timestep\n",
    "    Returns:\n",
    "        Tensor: negative log-likelihood for this example, a single float number\n",
    "    \"\"\"\n",
    "    # pred (bs)x(time)x(2D coords) --> (bs)x(mode=1)x(time)x(2D coords)\n",
    "    # create confidence (bs)x(mode=1)\n",
    "    batch_size, future_len, num_coords = pred.shape\n",
    "    confidences = pred.new_ones((batch_size, 1))\n",
    "    return pytorch_neg_multi_log_likelihood_batch(gt, pred.unsqueeze(1), confidences, avails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "#pytorch model definition. Here model outputs both multi-mode trajectory prediction & confidence of each trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model utils ---\n",
    "import torch\n",
    "from torchvision.models import resnet34\n",
    "from torch import nn\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "class LyftMultiModel(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg: Dict, num_modes=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO: support other than resnet18?\n",
    "        backbone = resnet34(pretrained=True, progress=True)\n",
    "        self.backbone = backbone\n",
    "\n",
    "        num_history_channels = (cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
    "        num_in_channels = 3 + num_history_channels\n",
    "\n",
    "        self.backbone.conv1 = nn.Conv2d(\n",
    "            num_in_channels,\n",
    "            self.backbone.conv1.out_channels,\n",
    "            kernel_size=self.backbone.conv1.kernel_size,\n",
    "            stride=self.backbone.conv1.stride,\n",
    "            padding=self.backbone.conv1.padding,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        # This is 512 for resnet18 and resnet34;\n",
    "        # And it is 2048 for the other resnets\n",
    "        backbone_out_features = 512\n",
    "\n",
    "        # X, Y coords for the future positions (output shape: Bx50x2)\n",
    "        self.future_len = cfg[\"model_params\"][\"future_num_frames\"]\n",
    "        num_targets = 2 * self.future_len\n",
    "\n",
    "        # You can add more layers here.\n",
    "        self.head = nn.Sequential(\n",
    "            # nn.Dropout(0.2),\n",
    "            nn.Linear(in_features=backbone_out_features, out_features=4096),\n",
    "        )\n",
    "\n",
    "        self.num_preds = num_targets * num_modes\n",
    "        self.num_modes = num_modes\n",
    "\n",
    "        self.logit = nn.Linear(4096, out_features=self.num_preds + num_modes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "\n",
    "        x = self.backbone.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.head(x)\n",
    "        x = self.logit(x)\n",
    "\n",
    "        # pred (bs)x(modes)x(time)x(2D coords)\n",
    "        # confidences (bs)x(modes)\n",
    "        bs, _ = x.shape\n",
    "        pred, confidences = torch.split(x, self.num_preds, dim=1)\n",
    "        pred = pred.view(bs, self.num_modes, self.future_len, 2)\n",
    "        assert confidences.shape == (bs, self.num_modes)\n",
    "        confidences = torch.softmax(confidences, dim=1)\n",
    "        return pred, confidences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LyftMultiModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyftMultiRegressor(nn.Module):\n",
    "    \"\"\"Single mode prediction\"\"\"\n",
    "\n",
    "    def __init__(self, predictor, lossfun=pytorch_neg_multi_log_likelihood_batch):\n",
    "        super().__init__()\n",
    "        self.predictor = predictor\n",
    "        self.lossfun = lossfun\n",
    "\n",
    "    def forward(self, image, targets, target_availabilities):\n",
    "        pred, confidences = self.predictor(image)\n",
    "        loss = self.lossfun(targets, pred, confidences, target_availabilities)\n",
    "        metrics = {\n",
    "            \"loss\": loss.item(),\n",
    "            \"nll\": pytorch_neg_multi_log_likelihood_batch(targets, pred, confidences, target_availabilities).item()\n",
    "        }\n",
    "        ppe.reporting.report(metrics, self)\n",
    "        return loss, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training with Ignite\n",
    "#I use pytorch-ignite for training abstraction.\n",
    "#Engine defines the 1 iteration of training update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training utils ---\n",
    "from ignite.engine import Engine\n",
    "\n",
    "\n",
    "def create_trainer(model, optimizer, device) -> Engine:\n",
    "    model.to(device)\n",
    "\n",
    "    def update_fn(engine, batch):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        loss, metrics = model(*[elem.to(device) for elem in batch])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return metrics\n",
    "    trainer = Engine(update_fn)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://github.com/grafi-tt/chaineripy/blob/master/chaineripy/extensions/print_report.py by @grafi-tt\n",
    "# Modified to work with pytorch_pfn_extras\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "\n",
    "from IPython.core.display import display\n",
    "from ipywidgets import HTML\n",
    "\n",
    "from pytorch_pfn_extras.training.extensions.print_report import PrintReport\n",
    "\n",
    "from pytorch_pfn_extras.training import extension\n",
    "from pytorch_pfn_extras.training.extensions import log_report \\\n",
    "    as log_report_module\n",
    "from pytorch_pfn_extras.training.extensions import util\n",
    "\n",
    "\n",
    "class PrintReportNotebook(PrintReport):\n",
    "\n",
    "    \"\"\"An extension to print the accumulated results.\n",
    "\n",
    "    This extension uses the log accumulated by a :class:`LogReport` extension\n",
    "    to print specified entries of the log in a human-readable format.\n",
    "\n",
    "    Args:\n",
    "        entries (list of str ot None): List of keys of observations to print.\n",
    "            If `None` is passed, automatically infer keys from reported dict.\n",
    "        log_report (str or LogReport): Log report to accumulate the\n",
    "            observations. This is either the name of a LogReport extensions\n",
    "            registered to the manager, or a LogReport instance to use\n",
    "            internally.\n",
    "        out: Stream to print the bar. Standard output is used by default.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, entries=None, log_report='LogReport', out=sys.stdout):\n",
    "        super(PrintReportNotebook, self).__init__(entries=entries, log_report=log_report, out=out)\n",
    "        self._widget = HTML()\n",
    "\n",
    "    def initialize(self, trainer):\n",
    "        display(self._widget)\n",
    "\n",
    "    @property\n",
    "    def widget(self):\n",
    "        return self._widget\n",
    "\n",
    "    def __call__(self, manager):\n",
    "        log_report = self.get_log_report(manager)\n",
    "        df = log_report.to_dataframe()\n",
    "        if self._infer_entries:\n",
    "            # --- update entries ---\n",
    "            self._update_entries(log_report)\n",
    "        self._widget.value = df[self._entries].to_html(index=False, na_rep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code referenced from https://github.com/grafi-tt/chaineripy/blob/master/chaineripy/extensions/progress_bar.py by @grafi-tt\n",
    "# Modified to work with pytorch_pfn_extras\n",
    "\n",
    "from pytorch_pfn_extras.training import extension, trigger\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from IPython.core.display import display\n",
    "from ipywidgets import FloatProgress, HBox, HTML, VBox\n",
    "\n",
    "\n",
    "class ProgressBarNotebook(extension.Extension):\n",
    "\n",
    "    \"\"\"Trainer extension to print a progress bar and recent training status.\n",
    "    This extension prints a progress bar at every call. It watches the current\n",
    "    iteration and epoch to print the bar.\n",
    "    Args:\n",
    "        training_length (tuple): Length of whole training. It consists of an\n",
    "            integer and either ``'epoch'`` or ``'iteration'``. If this value is\n",
    "            omitted and the stop trigger of the trainer is\n",
    "            :class:`IntervalTrigger`, this extension uses its attributes to\n",
    "            determine the length of the training.\n",
    "        update_interval (int): Number of iterations to skip printing the\n",
    "            progress bar.\n",
    "        bar_length (int): Length of the progress bar in characters.\n",
    "        out: Stream to print the bar. Standard output is used by default.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, training_length=None, update_interval=100,\n",
    "                 bar_length=50):\n",
    "        self._training_length = training_length\n",
    "        if training_length is not None:\n",
    "            self._init_status_template()\n",
    "        self._update_interval = update_interval\n",
    "        self._recent_timing = []\n",
    "\n",
    "        self._total_bar = FloatProgress(description='total',\n",
    "                                        min=0, max=1, value=0,\n",
    "                                        bar_style='info')\n",
    "        self._total_html = HTML()\n",
    "        self._epoch_bar = FloatProgress(description='this epoch',\n",
    "                                        min=0, max=1, value=0,\n",
    "                                        bar_style='info')\n",
    "        self._epoch_html = HTML()\n",
    "        self._status_html = HTML()\n",
    "\n",
    "        self._widget = VBox([HBox([self._total_bar, self._total_html]),\n",
    "                             HBox([self._epoch_bar, self._epoch_html]),\n",
    "                             self._status_html])\n",
    "\n",
    "    def initialize(self, manager):\n",
    "        if self._training_length is None:\n",
    "            t = manager._stop_trigger\n",
    "            if not isinstance(t, trigger.IntervalTrigger):\n",
    "                raise TypeError(\n",
    "                    'cannot retrieve the training length from %s' % type(t))\n",
    "            self._training_length = t.period, t.unit\n",
    "            self._init_status_template()\n",
    "\n",
    "        updater = manager.updater\n",
    "        self.update(updater.iteration, updater.epoch_detail)\n",
    "        display(self._widget)\n",
    "\n",
    "    def __call__(self, manager):\n",
    "        length, unit = self._training_length\n",
    "\n",
    "        updater = manager.updater\n",
    "        iteration, epoch_detail = updater.iteration, updater.epoch_detail\n",
    "\n",
    "        if unit == 'iteration':\n",
    "            is_finished = iteration == length\n",
    "        else:\n",
    "            is_finished = epoch_detail == length\n",
    "\n",
    "        if iteration % self._update_interval == 0 or is_finished:\n",
    "            self.update(iteration, epoch_detail)\n",
    "\n",
    "    def finalize(self):\n",
    "        if self._total_bar.value != 1:\n",
    "            self._total_bar.bar_style = 'warning'\n",
    "            self._epoch_bar.bar_style = 'warning'\n",
    "\n",
    "    @property\n",
    "    def widget(self):\n",
    "        return self._widget\n",
    "\n",
    "    def update(self, iteration, epoch_detail):\n",
    "        length, unit = self._training_length\n",
    "\n",
    "        recent_timing = self._recent_timing\n",
    "        now = time.time()\n",
    "\n",
    "        recent_timing.append((iteration, epoch_detail, now))\n",
    "\n",
    "        if unit == 'iteration':\n",
    "            rate = iteration / length\n",
    "        else:\n",
    "            rate = epoch_detail / length\n",
    "        self._total_bar.value = rate\n",
    "        self._total_html.value = \"{:6.2%}\".format(rate)\n",
    "\n",
    "        epoch_rate = epoch_detail - int(epoch_detail)\n",
    "        self._epoch_bar.value = epoch_rate\n",
    "        self._epoch_html.value = \"{:6.2%}\".format(epoch_rate)\n",
    "\n",
    "        status = self._status_template.format(iteration=iteration,\n",
    "                                              epoch=int(epoch_detail))\n",
    "\n",
    "        if rate == 1:\n",
    "            self._total_bar.bar_style = 'success'\n",
    "            self._epoch_bar.bar_style = 'success'\n",
    "\n",
    "        old_t, old_e, old_sec = recent_timing[0]\n",
    "        span = now - old_sec\n",
    "        if span != 0:\n",
    "            speed_t = (iteration - old_t) / span\n",
    "            speed_e = (epoch_detail - old_e) / span\n",
    "        else:\n",
    "            speed_t = float('inf')\n",
    "            speed_e = float('inf')\n",
    "\n",
    "        if unit == 'iteration':\n",
    "            estimated_time = (length - iteration) / speed_t\n",
    "        else:\n",
    "            estimated_time = (length - epoch_detail) / speed_e\n",
    "        estimate = ('{:10.5g} iters/sec. Estimated time to finish: {}.'\n",
    "                    .format(speed_t,\n",
    "                            datetime.timedelta(seconds=estimated_time)))\n",
    "\n",
    "        self._status_html.value = status + estimate\n",
    "\n",
    "        if len(recent_timing) > 100:\n",
    "            del recent_timing[0]\n",
    "\n",
    "    def _init_status_template(self):\n",
    "        self._status_template = (\n",
    "            '{iteration:10} iter, {epoch} epoch / %s %ss<br />' %\n",
    "            self._training_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Utils ---\n",
    "import yaml\n",
    "\n",
    "\n",
    "def save_yaml(filepath, content, width=120):\n",
    "    with open(filepath, 'w') as f:\n",
    "        yaml.dump(content, f, width=width)\n",
    "\n",
    "\n",
    "def load_yaml(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        content = yaml.safe_load(f)\n",
    "    return content\n",
    "\n",
    "\n",
    "class DotDict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\n",
    "\n",
    "    Refer: https://stackoverflow.com/questions/2352181/how-to-use-a-dot-to-access-members-of-dictionary/23689767#23689767\n",
    "    \"\"\"  # NOQA\n",
    "\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Lyft configs ---\n",
    "cfg = {\n",
    "    'format_version': 4,\n",
    "    'model_params': {\n",
    "        'model_architecture': 'resnet34',\n",
    "        'history_num_frames': 10,\n",
    "        'history_step_size': 1,\n",
    "        'history_delta_time': 0.1,\n",
    "        'future_num_frames': 50,\n",
    "        'future_step_size': 1,\n",
    "        'future_delta_time': 0.1\n",
    "    },\n",
    "\n",
    "    'raster_params': {\n",
    "        'raster_size': [534,534], # 224*224, 300*300, 350*350, 448*448, you can give a try to set 224*224\n",
    "        'pixel_size': [0.25, 0.25],\n",
    "        'ego_center': [0.25, 0.5],\n",
    "        'map_type': 'py_semantic',\n",
    "        'satellite_map_key': 'aerial_map/aerial_map.png',\n",
    "        'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
    "        'dataset_meta_key': 'meta.json',\n",
    "        'filter_agents_threshold': 0.5\n",
    "    },\n",
    "\n",
    "    'train_data_loader': {\n",
    "        'key': 'scenes/train.zarr',\n",
    "        'batch_size': 64, #  16, 32, you can give a try to set 16\n",
    "        'shuffle': True,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "\n",
    "    'valid_data_loader': {\n",
    "        'key': 'scenes/validate.zarr',\n",
    "        'batch_size': 64, #  16, 32, you can give a try to set 16\n",
    "        'shuffle': False,\n",
    "        'num_workers': 4\n",
    "    },\n",
    "\n",
    "    'train_params': {\n",
    "        'max_num_steps': 10000, # 10000, 20000, 30000, 600k, 700k, you can give a try to set 1000\n",
    "        'checkpoint_every_n_steps': 5000,\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags_dict = {\n",
    "    \"debug\": False,\n",
    "    # --- Data configs ---\n",
    "    \"l5kit_data_folder\": \"/Users/shuozhang/Downloads/lyft-motion-prediction-autonomous-vehicles/\", # change this\n",
    "    # --- Model configs ---\n",
    "    \"pred_mode\": \"multi\",\n",
    "    # --- Training configs ---\n",
    "    \"device\": \"cpu\", # change this to 'cuba:0' if put on server\n",
    "    \"out_dir\": \"results/multi_train\",\n",
    "    \"epoch\": 2, \n",
    "    \"snapshot_freq\": 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flags: {'debug': False, 'l5kit_data_folder': '/Users/shuozhang/Downloads/lyft-motion-prediction-autonomous-vehicles/', 'pred_mode': 'multi', 'device': 'cpu', 'out_dir': 'results/multi_train', 'epoch': 2, 'snapshot_freq': 50}\n"
     ]
    }
   ],
   "source": [
    "flags = DotDict(flags_dict)\n",
    "out_dir = Path(flags.out_dir)\n",
    "os.makedirs(str(out_dir), exist_ok=True)\n",
    "print(f\"flags: {flags_dict}\")\n",
    "save_yaml(out_dir / 'flags.yaml', flags_dict)\n",
    "save_yaml(out_dir / 'cfg.yaml', cfg)\n",
    "debug = flags.debu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset...\n",
      "train_zarr <class 'l5kit.data.zarr_dataset.ChunkedDataset'>\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   16265    |  4039527   | 320124624  |    38735988   |      112.19     |        248.36        |        79.25         |        24.83         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "# AgentDataset train: 22496709\n",
      "# ActualDataset train: 22496709\n"
     ]
    }
   ],
   "source": [
    "# # set env variable for data\n",
    "# os.environ[\"L5KIT_DATA_FOLDER\"] = flags.l5kit_data_folder\n",
    "# dm = LocalDataManager(None)\n",
    "\n",
    "# print(\"Load dataset...\")\n",
    "# train_cfg = cfg[\"train_data_loader\"]\n",
    "\n",
    "# # Rasterizer\n",
    "# rasterizer = build_rasterizer(cfg, dm)\n",
    "\n",
    "# # Train dataset/dataloader\n",
    "# def transform(batch):\n",
    "#     return batch[\"image\"], batch[\"target_positions\"], batch[\"target_availabilities\"]\n",
    "\n",
    "\n",
    "# train_path = \"scenes/sample.zarr\" if debug else train_cfg[\"key\"]\n",
    "# train_zarr = ChunkedDataset(dm.require(train_path)).open()\n",
    "# print(\"train_zarr\", type(train_zarr))\n",
    "# train_agent_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
    "# train_dataset = TransformDataset(train_agent_dataset, transform)\n",
    "# if debug:\n",
    "#     # Only use 1000 dataset for fast check...\n",
    "#     train_dataset = Subset(train_dataset, np.arange(1000))\n",
    "# train_loader = DataLoader(train_dataset,\n",
    "#                           shuffle=train_cfg[\"shuffle\"],\n",
    "#                           batch_size=train_cfg[\"batch_size\"],\n",
    "#                           num_workers=train_cfg[\"num_workers\"])\n",
    "# print(train_agent_dataset)\n",
    "# print(\"# AgentDataset train:\", len(train_agent_dataset))\n",
    "# print(\"# ActualDataset train:\", len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Dict\n",
    "\n",
    "# from tempfile import gettempdir\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from torch import nn, optim\n",
    "# from torch.utils.data import DataLoader\n",
    "# from torchvision.models.resnet import resnet50\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# from l5kit.configs import load_config_data\n",
    "# from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "# from l5kit.dataset import AgentDataset, EgoDataset\n",
    "# from l5kit.rasterization import build_rasterizer\n",
    "# from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "# from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "# from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "# from l5kit.geometry import transform_points\n",
    "# from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "# from prettytable import PrettyTable\n",
    "# from pathlib import Path\n",
    "\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "copying: 100%|██████████| 16220/16220 [04:00<00:00, 67.30it/s]\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/evaluation/extract_ground_truth.py:59: RuntimeWarning:\n",
      "\n",
      "you're running with a custom agents_mask\n",
      "\n",
      "extracting GT: 100%|██████████| 94694/94694 [06:46<00:00, 233.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# # ===== GENERATE AND LOAD CHOPPED DATASET\n",
    "# valid_cfg = cfg[\"valid_data_loader\"]\n",
    "# valid_path = \"scenes/sample.zarr\" if debug else valid_cfg[\"key\"]\n",
    "# num_frames_to_chop = 100\n",
    "# valid_base_path = create_chopped_dataset(dm.require(valid_cfg[\"key\"]), cfg[\"raster_params\"][\"filter_agents_threshold\"], \n",
    "#                               num_frames_to_chop, cfg[\"model_params\"][\"future_num_frames\"], MIN_FUTURE_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning:\n",
      "\n",
      "you're running with a custom agents_mask\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   16220    |  1622000   | 125423254  |    11733321   |      45.06      |        100.00        |        77.33         |        10.00         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "# AgentDataset valid: 94694\n"
     ]
    }
   ],
   "source": [
    "# valid_zarr_path = str(Path(valid_base_path) / Path(dm.require(valid_cfg[\"key\"])).name)\n",
    "# valid_mask_path = str(Path(valid_base_path) / \"mask.npz\")\n",
    "# valid_gt_path = str(Path(valid_base_path) / \"gt.csv\")\n",
    "\n",
    "# valid_zarr = ChunkedDataset(valid_zarr_path).open()\n",
    "# valid_mask = np.load(valid_mask_path)[\"arr_0\"]\n",
    "# # ===== INIT DATASET AND LOAD MASK\n",
    "# valid_agent_dataset = AgentDataset(cfg, valid_zarr, rasterizer, agents_mask=valid_mask)\n",
    "# valid_dataset = TransformDataset(valid_agent_dataset, transform)\n",
    "# valid_loader = DataLoader(valid_dataset,\n",
    "#                           shuffle=valid_cfg[\"shuffle\"],\n",
    "#                           batch_size=valid_cfg[\"batch_size\"],\n",
    "#                           num_workers=valid_cfg[\"num_workers\"])\n",
    "\n",
    "# print(valid_agent_dataset)\n",
    "# print(\"# AgentDataset valid:\", len(valid_agent_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ActualDataset valid: 94694\n"
     ]
    }
   ],
   "source": [
    "# print(\"# ActualDataset valid:\", len(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare model & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(flags.device)\n",
    "\n",
    "if flags.pred_mode == \"multi\":\n",
    "    predictor = LyftMultiModel(cfg)\n",
    "    model = LyftMultiRegressor(predictor)\n",
    "else:\n",
    "    raise ValueError(f\"[ERROR] Unexpected value flags.pred_mode={flags.pred_mode}\")\n",
    "\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write training code\n",
    "#pytorch-ignite & pytorch-pfn-extras are used here.\n",
    "\n",
    "#pytorch/ignite: It provides abstraction for writing training loop.\n",
    "#pfnet/pytorch-pfn-extras: It provides several \"extensions\" useful for training.\n",
    "#Useful for logging, printing, evaluating, saving the model, scheduling the learning rate during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train setup\n",
    "# trainer = create_trainer(model, optimizer, device)\n",
    "\n",
    "\n",
    "# def eval_func(*batch):\n",
    "#     loss, metrics = model(*[elem.to(device) for elem in batch])\n",
    "\n",
    "\n",
    "# valid_evaluator = E.Evaluator(\n",
    "#     valid_loader,\n",
    "#     model,\n",
    "#     progress_bar=True,\n",
    "#     eval_func=eval_func,\n",
    "# )\n",
    "\n",
    "# log_trigger = (10 if debug else 1000, \"iteration\")\n",
    "# log_report = E.LogReport(trigger=log_trigger)\n",
    "\n",
    "\n",
    "# extensions = [\n",
    "#     log_report,  # Save `log` to file\n",
    "#     valid_evaluator,  # Run evaluation for valid dataset in each epoch.\n",
    "#     # E.FailOnNonNumber()  # Stop training when nan is detected.\n",
    "# ]\n",
    "\n",
    "# is_notebook = False  # Make it False when you run code in local machine using console.\n",
    "# if is_notebook:\n",
    "#     extensions.extend([\n",
    "#         ProgressBarNotebook(update_interval=10 if debug else 100),  # Show progress bar during training\n",
    "#         PrintReportNotebook(),  # Show \"log\" on jupyter notebook  \n",
    "#     ])\n",
    "# else:\n",
    "#     extensions.extend([\n",
    "#         E.ProgressBar(update_interval=10 if debug else 100),  # Show progress bar during training\n",
    "#         E.PrintReport(),  # Print \"log\" to terminal\n",
    "#     ])\n",
    "\n",
    "\n",
    "# epoch = flags.epoch\n",
    "\n",
    "# models = {\"main\": model}\n",
    "# optimizers = {\"main\": optimizer}\n",
    "# manager = IgniteExtensionsManager(\n",
    "#     trainer,\n",
    "#     models,\n",
    "#     optimizers,\n",
    "#     epoch,\n",
    "#     extensions=extensions,\n",
    "#     out_dir=str(out_dir),\n",
    "# )\n",
    "# # Save predictor.pt every epoch\n",
    "# manager.extend(E.snapshot_object(predictor, \"predictor.pt\"),\n",
    "#                trigger=(flags.snapshot_freq, \"iteration\"))\n",
    "# # Check & Save best validation predictor.pt every epoch\n",
    "# # manager.extend(E.snapshot_object(predictor, \"best_predictor.pt\"),\n",
    "# #                trigger=MinValueTrigger(\"validation/main/nll\", trigger=(flags.snapshot_freq, \"iteration\")))\n",
    "# # --- lr scheduler ---\n",
    "# # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "# #     optimizer, mode='min', factor=0.7, patience=5, min_lr=1e-10)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "#     optimizer, gamma=0.99999)\n",
    "# manager.extend(lambda manager: scheduler.step(), trigger=(1, \"iteration\"))\n",
    "# # Show \"lr\" column in log\n",
    "# manager.extend(E.observe_lr(optimizer=optimizer), trigger=log_trigger)\n",
    "\n",
    "# trainer.run(train_loader, max_epochs=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = log_report.to_dataframe()\n",
    "# df.to_csv(\"log.csv\", index=False)\n",
    "# df[[\"epoch\", \"iteration\", \"main/loss\", \"main/nll\", \"validation/main/loss\", \"validation/main/nll\", \"lr\", \"elapsed_time\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extensions - Each role:\n",
    "\n",
    "# ProgressBar (ProgressBarNotebook): Shows training progress in formatted style.\n",
    "# LogReport: Logging metrics reported by ppe.reporter.report \n",
    "#(see LyftMultiRegressor for reporting point) method and save to log file. \n",
    "#It automatically collects reported value in each iteration and saves the \"mean\" of reported value \n",
    "#for regular frequency (for example every 1 epoch).\n",
    "# PrintReport (PrintReportNotebook): Prints the value which LogReport collected in formatted style.\n",
    "# Evaluator: Evaluate on validation dataset.\n",
    "# snapshot_object: Saves the object. Here the model is saved in regular interval flags.snapshot_freq.\n",
    "#Even you quit training using Ctrl+C without finishing all the epoch, \n",
    "#the intermediate trained model is saved and you can use it for inference.\n",
    "# lambda function with scheduler.step(): You can invoke any function in regular interval specified by trigger.\n",
    "#Here exponential decay of learning rate is applied by calling scheduler.step() every iteration.\n",
    "# observe_lr: LogReport will check optimizer's learning rate using this extension.\n",
    "#So you can follow how the learning rate changed through the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug result: \n",
    "# iteration\tmain/loss\tmain/nll\tlr\t    validation/main/loss\tvalidation/main/nll\telapsed_time\n",
    "# 10\t   2566.690948\t2566.690948\t0.001000\t\t\t                               10.377875\n",
    "# 20\t   1540.009851\t1540.009851\t0.001000\t\t\t                               17.131299\n",
    "# 30\t   970.311111\t970.311111\t0.001000\t\t\t                               25.948778\n",
    "# 40\t   1260.554537\t1260.554537\t0.001000\t\t\t                               32.972381\n",
    "# 50\t   1403.084926\t1403.084926\t0.001000\t\t\t                               41.940716\n",
    "# 60\t   1522.389905\t1522.389905\t0.000999\t\t\t                               49.204889\n",
    "# 70\t   1106.671555\t1106.671555\t0.000999\t\t\t                               57.684869\n",
    "# 80\t   856.877580\t856.877580\t0.000999\t\t\t                               64.952417\n",
    "# 90\t   957.383397\t957.383397\t0.000999\t4912.747314\t      4912.747314\t       79.925156\n",
    "# 100\t   911.428769\t911.428769\t0.000999\t\t\t                               86.664308\n",
    "# 110\t   441.032510\t441.032510\t0.000999\t\t\t                               95.298566\n",
    "# 120\t   332.250836\t332.250836\t0.000999\t\t\t                              102.593534\n",
    "# 130\t   814.817209\t814.817209\t0.000999\t\t\t                              111.937015\n",
    "# 140\t   1075.804512\t1075.804512\t0.000999\t\t\t                              118.627421\n",
    "# 150\t   1094.629809\t1094.629809\t0.000999\t\t\t                              127.598126\n",
    "# 160\t  627.256924\t627.256924\t0.000998\t\t\t                              134.250497"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703022.15625"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22496709/64*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(predictor, data_loader):\n",
    "    predictor.eval()\n",
    "\n",
    "    pred_coords_list = []\n",
    "    confidences_list = []\n",
    "    timestamps_list = []\n",
    "    track_id_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dataiter = tqdm(data_loader)\n",
    "        for data in dataiter:\n",
    "            image = data[\"image\"].to(device)\n",
    "            # target_availabilities = data[\"target_availabilities\"].to(device)\n",
    "            # targets = data[\"target_positions\"].to(device)\n",
    "            preds, confidences = predictor(image)\n",
    "            # convert agent coordinates into world offsets\n",
    "            preds = preds.cpu().numpy().copy()\n",
    "            world_from_agents = data[\"world_from_agent\"].numpy()\n",
    "            centroids = data[\"centroid\"].numpy()\n",
    "            coords_offset = []\n",
    "        \n",
    "        # convert into world coordinates and compute offsets\n",
    "            for idx in range(len(preds)):\n",
    "                for mode in range(3):\n",
    "                    preds[idx, mode, :, :] = transform_points(preds[idx, mode, :, :], world_from_agents[idx]) - centroids[idx][:2]\n",
    "            \n",
    "            confidences_list.append(confidences.cpu().numpy().copy())\n",
    "            timestamps_list.append(data[\"timestamp\"].numpy().copy())\n",
    "            track_id_list.append(data[\"track_id\"].numpy().copy())\n",
    "            pred_coords_list.append(preds.copy())\n",
    "    timestamps = np.concatenate(timestamps_list)\n",
    "    track_ids = np.concatenate(track_id_list)\n",
    "    coords = np.concatenate(pred_coords_list)\n",
    "    confs = np.concatenate(confidences_list)\n",
    "    return timestamps, track_ids, coords, confs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load dataset...\n",
      "Loading from scenes/test.zarr\n",
      "test_zarr <class 'l5kit.data.zarr_dataset.ChunkedDataset'>\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   11314    |  1131400   |  88594921  |    7854144    |      31.43      |        100.00        |        78.31         |        10.00         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "# AgentDataset test: 71122\n",
      "# ActualDataset test: 71122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning:\n",
      "\n",
      "you're running with a custom agents_mask\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set env variable for data\n",
    "l5kit_data_folder = \"/Users/shuozhang/Downloads/lyft-motion-prediction-autonomous-vehicles\"\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = l5kit_data_folder\n",
    "dm = LocalDataManager(None)\n",
    "\n",
    "print(\"Load dataset...\")\n",
    "default_test_cfg = {\n",
    "    'key': 'scenes/test.zarr',\n",
    "    'batch_size': 64,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 4\n",
    "}\n",
    "test_cfg = cfg.get(\"test_data_loader\", default_test_cfg)\n",
    "\n",
    "# Rasterizer\n",
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "\n",
    "test_path = test_cfg[\"key\"]\n",
    "print(f\"Loading from {test_path}\")\n",
    "test_zarr = ChunkedDataset(dm.require(test_path)).open()\n",
    "print(\"test_zarr\", type(test_zarr))\n",
    "test_mask = np.load(f\"{l5kit_data_folder}/scenes/mask.npz\")[\"arr_0\"]\n",
    "test_agent_dataset = AgentDataset(cfg, test_zarr, rasterizer, agents_mask=test_mask)\n",
    "test_dataset = test_agent_dataset\n",
    "if debug:\n",
    "    # Only use 100 dataset for fast check...\n",
    "    test_dataset = Subset(test_dataset, np.arange(100))\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    shuffle=test_cfg[\"shuffle\"],\n",
    "    batch_size=test_cfg[\"batch_size\"],\n",
    "    num_workers=test_cfg[\"num_workers\"],\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "print(test_agent_dataset)\n",
    "print(\"# AgentDataset test:\", len(test_agent_dataset))\n",
    "print(\"# ActualDataset test:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新跑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /Users/shuozhang/Downloads/predictor_resent34_534_batch64_31800.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LyftMultiModel(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(25, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
       "  )\n",
       "  (logit): Linear(in_features=4096, out_features=303, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(flags.device)\n",
    "\n",
    "if flags.pred_mode == \"multi\":\n",
    "    predictor = LyftMultiModel(cfg)\n",
    "else:\n",
    "    raise ValueError(f\"[ERROR] Unexpected value flags.pred_mode={flags.pred_mode}\")\n",
    "\n",
    "pt_path = \"/Users/shuozhang/Downloads/predictor_resent34_534_batch64_31800.pt\" \n",
    "# change the file for pt\n",
    "print(f\"Loading from {pt_path}\")\n",
    "predictor.load_state_dict(torch.load(pt_path,map_location=torch.device('cpu')))\n",
    "predictor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1112 [00:00<?, ?it/s]/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "100%|██████████| 1112/1112 [11:16:05<00:00, 36.48s/it]  \n"
     ]
    }
   ],
   "source": [
    "timestamps, track_ids, coords, confs = run_prediction(predictor, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to model8_2_64.csv\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"model8_2_64.csv\"\n",
    "write_pred_csv(\n",
    "    csv_path,\n",
    "    timestamps=timestamps,\n",
    "    track_ids=track_ids,\n",
    "    coords=coords,\n",
    "    confs=confs)\n",
    "print(f\"Saved to {csv_path}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to model8_2.csv\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"model8_2_32.csv\"\n",
    "write_pred_csv(\n",
    "    csv_path,\n",
    "    timestamps=timestamps,\n",
    "    track_ids=track_ids,\n",
    "    coords=coords,\n",
    "    confs=confs)\n",
    "print(f\"Saved to {csv_path}\" ) #67.916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /Users/shuozhang/Downloads/predictor_resent34_534_batch64_66000.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LyftMultiModel(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(25, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
       "  )\n",
       "  (logit): Linear(in_features=4096, out_features=303, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(flags.device)\n",
    "\n",
    "if flags.pred_mode == \"multi\":\n",
    "    predictor = LyftMultiModel(cfg)\n",
    "else:\n",
    "    raise ValueError(f\"[ERROR] Unexpected value flags.pred_mode={flags.pred_mode}\")\n",
    "\n",
    "pt_path = \"/Users/shuozhang/Downloads/predictor_resent34_534_batch64_66000.pt\" \n",
    "# change the file for pt\n",
    "print(f\"Loading from {pt_path}\")\n",
    "predictor.load_state_dict(torch.load(pt_path,map_location=torch.device('cpu')))\n",
    "predictor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1112 [00:00<?, ?it/s]/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "100%|██████████| 1112/1112 [11:36:45<00:00, 37.60s/it]  \n"
     ]
    }
   ],
   "source": [
    "timestamps, track_ids, coords, confs = run_prediction(predictor, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to model8_4.csv\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"model8_4.csv\"\n",
    "write_pred_csv(\n",
    "    csv_path,\n",
    "    timestamps=timestamps,\n",
    "    track_ids=track_ids,\n",
    "    coords=coords,\n",
    "    confs=confs)\n",
    "print(f\"Saved to {csv_path}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /Users/shuozhang/Downloads/predictor_resent34_534_batch64_97000.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LyftMultiModel(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(25, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
       "  )\n",
       "  (logit): Linear(in_features=4096, out_features=303, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(flags.device)\n",
    "\n",
    "if flags.pred_mode == \"multi\":\n",
    "    predictor = LyftMultiModel(cfg)\n",
    "else:\n",
    "    raise ValueError(f\"[ERROR] Unexpected value flags.pred_mode={flags.pred_mode}\")\n",
    "\n",
    "pt_path = \"/Users/shuozhang/Downloads/predictor_resent34_534_batch64_97000.pt\" \n",
    "# change the file for pt\n",
    "print(f\"Loading from {pt_path}\")\n",
    "predictor.load_state_dict(torch.load(pt_path,map_location=torch.device('cpu')))\n",
    "predictor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1112 [00:00<?, ?it/s]/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "100%|██████████| 1112/1112 [12:10:03<00:00, 39.39s/it]  \n"
     ]
    }
   ],
   "source": [
    "timestamps, track_ids, coords, confs = run_prediction(predictor, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to model8_6.csv\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"model8_6.csv\"\n",
    "write_pred_csv(\n",
    "    csv_path,\n",
    "    timestamps=timestamps,\n",
    "    track_ids=track_ids,\n",
    "    coords=coords,\n",
    "    confs=confs)\n",
    "print(f\"Saved to {csv_path}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /Users/shuozhang/Downloads/predictor_resent34_534_batch64_112000.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LyftMultiModel(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(25, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
       "  )\n",
       "  (logit): Linear(in_features=4096, out_features=303, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(flags.device)\n",
    "\n",
    "if flags.pred_mode == \"multi\":\n",
    "    predictor = LyftMultiModel(cfg)\n",
    "else:\n",
    "    raise ValueError(f\"[ERROR] Unexpected value flags.pred_mode={flags.pred_mode}\")\n",
    "\n",
    "pt_path = \"/Users/shuozhang/Downloads/predictor_resent34_534_batch64_112000.pt\" \n",
    "# change the file for pt\n",
    "print(f\"Loading from {pt_path}\")\n",
    "predictor.load_state_dict(torch.load(pt_path,map_location=torch.device('cpu')))\n",
    "predictor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1112 [00:00<?, ?it/s]/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "100%|██████████| 1112/1112 [11:15:48<00:00, 36.46s/it]  \n"
     ]
    }
   ],
   "source": [
    "timestamps, track_ids, coords, confs = run_prediction(predictor, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to model8_7.csv\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"model8_7.csv\"\n",
    "write_pred_csv(\n",
    "    csv_path,\n",
    "    timestamps=timestamps,\n",
    "    track_ids=track_ids,\n",
    "    coords=coords,\n",
    "    confs=confs)\n",
    "print(f\"Saved to {csv_path}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /Users/shuozhang/Downloads/predictor_resent34_534_batch64_215000.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LyftMultiModel(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(25, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
       "  )\n",
       "  (logit): Linear(in_features=4096, out_features=303, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(flags.device)\n",
    "\n",
    "if flags.pred_mode == \"multi\":\n",
    "    predictor = LyftMultiModel(cfg)\n",
    "else:\n",
    "    raise ValueError(f\"[ERROR] Unexpected value flags.pred_mode={flags.pred_mode}\")\n",
    "\n",
    "pt_path = \"/Users/shuozhang/Downloads/predictor_resent34_534_batch64_215000.pt\" \n",
    "# change the file for pt\n",
    "print(f\"Loading from {pt_path}\")\n",
    "predictor.load_state_dict(torch.load(pt_path,map_location=torch.device('cpu')))\n",
    "predictor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1112 [00:00<?, ?it/s]/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "100%|██████████| 1112/1112 [11:41:59<00:00, 37.88s/it]  \n"
     ]
    }
   ],
   "source": [
    "timestamps, track_ids, coords, confs = run_prediction(predictor, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to model8_14.csv\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"model8_14.csv\"\n",
    "write_pred_csv(\n",
    "    csv_path,\n",
    "    timestamps=timestamps,\n",
    "    track_ids=track_ids,\n",
    "    coords=coords,\n",
    "    confs=confs)\n",
    "print(f\"Saved to {csv_path}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /Users/shuozhang/Downloads/predictor_resent34_534_batch64_239000.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LyftMultiModel(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(25, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
       "  )\n",
       "  (logit): Linear(in_features=4096, out_features=303, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(flags.device)\n",
    "\n",
    "if flags.pred_mode == \"multi\":\n",
    "    predictor = LyftMultiModel(cfg)\n",
    "else:\n",
    "    raise ValueError(f\"[ERROR] Unexpected value flags.pred_mode={flags.pred_mode}\")\n",
    "\n",
    "pt_path = \"/Users/shuozhang/Downloads/predictor_resent34_534_batch64_239000.pt\" \n",
    "# change the file for pt\n",
    "print(f\"Loading from {pt_path}\")\n",
    "predictor.load_state_dict(torch.load(pt_path,map_location=torch.device('cpu')))\n",
    "predictor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1112 [00:00<?, ?it/s]/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "100%|██████████| 1112/1112 [12:19:51<00:00, 39.92s/it]  \n"
     ]
    }
   ],
   "source": [
    "timestamps, track_ids, coords, confs = run_prediction(predictor, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to model8_16.csv\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"model8_16.csv\"\n",
    "write_pred_csv(\n",
    "    csv_path,\n",
    "    timestamps=timestamps,\n",
    "    track_ids=track_ids,\n",
    "    coords=coords,\n",
    "    confs=confs)\n",
    "print(f\"Saved to {csv_path}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /Users/shuozhang/Downloads/predictor_resent34_534_batch64_266000.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LyftMultiModel(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(25, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
       "  )\n",
       "  (logit): Linear(in_features=4096, out_features=303, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(flags.device)\n",
    "\n",
    "if flags.pred_mode == \"multi\":\n",
    "    predictor = LyftMultiModel(cfg)\n",
    "else:\n",
    "    raise ValueError(f\"[ERROR] Unexpected value flags.pred_mode={flags.pred_mode}\")\n",
    "\n",
    "pt_path = \"/Users/shuozhang/Downloads/predictor_resent34_534_batch64_266000.pt\" \n",
    "# change the file for pt\n",
    "print(f\"Loading from {pt_path}\")\n",
    "predictor.load_state_dict(torch.load(pt_path,map_location=torch.device('cpu')))\n",
    "predictor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1112 [00:00<?, ?it/s]/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "100%|██████████| 1112/1112 [11:46:21<00:00, 38.11s/it]  \n"
     ]
    }
   ],
   "source": [
    "timestamps, track_ids, coords, confs = run_prediction(predictor, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to model8_19.csv\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"model8_19.csv\"\n",
    "write_pred_csv(\n",
    "    csv_path,\n",
    "    timestamps=timestamps,\n",
    "    track_ids=track_ids,\n",
    "    coords=coords,\n",
    "    confs=confs)\n",
    "print(f\"Saved to {csv_path}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from /Users/shuozhang/Downloads/predictor_resent34_534_batch64_281000.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LyftMultiModel(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(25, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
       "  )\n",
       "  (logit): Linear(in_features=4096, out_features=303, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(flags.device)\n",
    "\n",
    "if flags.pred_mode == \"multi\":\n",
    "    predictor = LyftMultiModel(cfg)\n",
    "else:\n",
    "    raise ValueError(f\"[ERROR] Unexpected value flags.pred_mode={flags.pred_mode}\")\n",
    "\n",
    "pt_path = \"/Users/shuozhang/Downloads/predictor_resent34_534_batch64_281000.pt\" \n",
    "# change the file for pt\n",
    "print(f\"Loading from {pt_path}\")\n",
    "predictor.load_state_dict(torch.load(pt_path,map_location=torch.device('cpu')))\n",
    "predictor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1112 [00:00<?, ?it/s]/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "100%|██████████| 1112/1112 [15:26:04<00:00, 49.97s/it]   \n"
     ]
    }
   ],
   "source": [
    "timestamps, track_ids, coords, confs = run_prediction(predictor, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to model8_20.csv\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"model8_20.csv\"\n",
    "write_pred_csv(\n",
    "    csv_path,\n",
    "    timestamps=timestamps,\n",
    "    track_ids=track_ids,\n",
    "    coords=coords,\n",
    "    confs=confs)\n",
    "print(f\"Saved to {csv_path}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration   main/loss   main/nll    lr          elapsed_time..]  0.14%\n",
    "# 1000        246.608     246.608     0.00099006  2565.82       \n",
    "# 2000        134.495     134.495     0.000980208  5040.86       \n",
    "# 3000        124.541     124.541     0.000970455  7578.24       \n",
    "# 4000        113.603     113.603     0.000960799  10112.7       \n",
    "# 5000        102.806     102.806     0.000951239  12566         \n",
    "# 6000        80.8249     80.8249     0.000941774  15043.2       \n",
    "# 7000        69.7267     69.7267     0.000932403  17604.6       \n",
    "# 8000        65.1087     65.1087     0.000923125  20250.5       \n",
    "# 9000        56.577      56.577      0.00091394  23009.6       \n",
    "# 10000       48.5363     48.5363     0.000904846  25476.3       \n",
    "# 11000       46.8095     46.8095     0.000895843  27943.2       \n",
    "# 12000       44.5082     44.5082     0.000886929  30435.1       \n",
    "# 13000       40.8986     40.8986     0.000878104  32903.5       \n",
    "# 14000       39.1917     39.1917     0.000869366  35379         \n",
    "# 15000       38.335      38.335      0.000860716  37877.8       \n",
    "# 16000       35.9245     35.9245     0.000852152  40568.5       \n",
    "# 17000       34.0565     34.0565     0.000843673  43390.8       \n",
    "# 18000       32.0918     32.0918     0.000835278  46231.3       \n",
    "# 19000       30.5138     30.5138     0.000826967  49064.1       \n",
    "# 20000       28.8933     28.8933     0.000818738  51734.6       \n",
    "# 21000       29.4042     29.4042     0.000810592  54252.5       \n",
    "# 22000       28.8084     28.8084     0.000802526  56748.2       \n",
    "# 23000       26.66       26.66       0.000794541  59256.8       \n",
    "# 24000       26.7328     26.7328     0.000786635  61746.2       \n",
    "# 25000       26.9661     26.9661     0.000778808  64237.5       \n",
    "# 26000       24.2706     24.2706     0.000771058  66725.8       \n",
    "# 27000       23.7597     23.7597     0.000763386  69233.3       \n",
    "# 28000       23.5241     23.5241     0.00075579  71717.9       \n",
    "# 29000       23.5805     23.5805     0.00074827  74203.5       \n",
    "# 30000       23.0245     23.0245     0.000740825  76675.5       \n",
    "# 31000       22.6089     22.6089     0.000733453  79151.4       \n",
    "# 32000       21.9162     21.9162     0.000726155  81638.5       \n",
    "# 33000       22.5695     22.5695     0.00071893  84129.7       \n",
    "# 34000       21.5089     21.5089     0.000711776  86610.3       \n",
    "# 35000       20.805      20.805      0.000704694  89115.4       \n",
    "# 36000       20.3881     20.3881     0.000697682  91619.5       \n",
    "# 37000       20.6398     20.6398     0.00069074  94139.5       \n",
    "# 38000       21.3689     21.3689     0.000683867  96663.5       \n",
    "# 39000       20.374      20.374      0.000677062  99472.1       \n",
    "# 40000       19.7404     19.7404     0.000670325  102378        \n",
    "# 41000       19.2853     19.2853     0.000663656  105261        \n",
    "# 42000       19.8043     19.8043     0.000657052  108158        \n",
    "# 43000       19.3634     19.3634     0.000650514  111026        \n",
    "# 44000       19.3609     19.3609     0.000644041  113891        \n",
    "# 45000       19.0078     19.0078     0.000637633  116727        \n",
    "# 46000       19.6359     19.6359     0.000631289  119591        \n",
    "# 47000       18.2572     18.2572     0.000625007  122515        \n",
    "# 48000       17.9629     17.9629     0.000618788  125078        \n",
    "# 49000       18.8436     18.8436     0.000612631  127557        \n",
    "# 50000       17.9263     17.9263     0.000606535  129969        \n",
    "# 51000       17.6406     17.6406     0.0006005   132392        \n",
    "# 52000       17.7651     17.7651     0.000594525  134789        \n",
    "# 53000       17.915      17.915      0.000588609  137191        \n",
    "# 54000       17.3214     17.3214     0.000582753  139649        \n",
    "# 55000       16.7883     16.7883     0.000576954  142078        \n",
    "# 56000       17.0955     17.0955     0.000571213  144482        \n",
    "# 57000       16.9098     16.9098     0.000565529  146903        \n",
    "# 58000       16.9515     16.9515     0.000559902  149316        \n",
    "# 59000       15.9669     15.9669     0.000554331  151750        \n",
    "# 60000       16.5633     16.5633     0.000548815  154175        \n",
    "# 61000       15.828      15.828      0.000543355  156617        \n",
    "# 62000       16.3236     16.3236     0.000537948  159033        \n",
    "# 63000       16.8483     16.8483     0.000532595  161431        \n",
    "# 64000       16.213      16.213      0.000527296  163837 \n",
    "# 65000       15.9555     15.9555     0.000522049  166304        \n",
    "# 66000       16.2599     16.2599     0.000516855  168717        \n",
    "# 67000       15.2751     15.2751     0.000511712  171145        \n",
    "# 68000       16.1139     16.1139     0.00050662  173633        \n",
    "# 69000       16.1092     16.1092     0.000501579  176120        \n",
    "# 70000       15.6411     15.6411     0.000496589  178625        \n",
    "# 71000       15.8849     15.8849     0.000491647  181105        \n",
    "# 72000       15.5516     15.5516     0.000486755  183523        \n",
    "# 73000       15.0486     15.0486     0.000481912  186146        \n",
    "# 74000       15.3272     15.3272     0.000477117  189065        \n",
    "# 75000       14.8535     14.8535     0.00047237  191473        \n",
    "# 76000       15.2367     15.2367     0.000467669  193909        \n",
    "# 77000       15.3614     15.3614     0.000463016  196310        \n",
    "# 78000       15.3999     15.3999     0.000458409  198705        \n",
    "# 79000       15.2488     15.2488     0.000453848  201122        \n",
    "# 80000       14.3557     14.3557     0.000449332  203519        \n",
    "# 81000       14.6494     14.6494     0.000444861  206163        \n",
    "# 82000       15.128      15.128      0.000440434  209075        \n",
    "# 83000       15.0283     15.0283     0.000436052  211951        \n",
    "# 84000       14.2413     14.2413     0.000431713  214847        \n",
    "# 85000       14.6462     14.6462     0.000427417  217497        \n",
    "# 86000       14.2119     14.2119     0.000423164  219899      \n",
    "# 87000       14.5498     14.5498     0.000418954  222433        \n",
    "# 88000       14.0853     14.0853     0.000414785  225279        \n",
    "# 89000       13.7793     13.7793     0.000410658  228225        \n",
    "# 90000       14.3565     14.3565     0.000406572  231161        \n",
    "# 91000       14.5311     14.5311     0.000402526  234113        \n",
    "# 92000       13.9809     13.9809     0.000398521  237093        \n",
    "# 93000       14.332      14.332      0.000394556  240080        \n",
    "# 94000       14.0843     14.0843     0.00039063  243038        \n",
    "# 95000       13.8302     13.8302     0.000386743  246000        \n",
    "# 96000       13.8213     13.8213     0.000382895  248955        \n",
    "# 97000       13.5921     13.5921     0.000379085  251906        \n",
    "# 98000       14.7321     14.7321     0.000375313  254925        \n",
    "# 99000       13.7742     13.7742     0.000371579  257925        \n",
    "# 100000      13.8036     13.8036     0.000367881  260884        \n",
    "# 101000      13.9826     13.9826     0.000364221  263935        \n",
    "# 102000      13.2042     13.2042     0.000360597  266938        \n",
    "# 103000      13.0243     13.0243     0.000357009  269999        \n",
    "# 104000      13.6645     13.6645     0.000353456  272968        \n",
    "# 105000      12.9524     12.9524     0.000349939  276035        \n",
    "# 106000      13.3976     13.3976     0.000346457  279091        \n",
    "# 107000      12.7807     12.7807     0.00034301  282152        \n",
    "# 108000      13.8308     13.8308     0.000339597  285194        \n",
    "# 109000      12.8637     12.8637     0.000336218  288160        \n",
    "# 110000      12.9654     12.9654     0.000332873  291140        \n",
    "# 111000      12.86       12.86       0.00032956  294150        \n",
    "# 112000      12.9481     12.9481     0.000326281  297231  \n",
    "# 113000      12.5697     12.5697     0.000323035  300266        \n",
    "# 114000      12.5993     12.5993     0.00031982  303365        \n",
    "# 115000      12.6543     12.6543     0.000316638  306453        \n",
    "# 116000      12.9969     12.9969     0.000313487  309586        \n",
    "# 117000      12.8993     12.8993     0.000310368  312728        \n",
    "# 118000      12.9749     12.9749     0.00030728  315897        \n",
    "# 119000      12.8778     12.8778     0.000304222  319075        \n",
    "# 120000      12.413      12.413      0.000301195  322196        \n",
    "# 121000      12.7178     12.7178     0.000298198  325318        \n",
    "# 122000      12.2412     12.2412     0.000295231  328456        \n",
    "# 123000      12.3016     12.3016     0.000292294  331568        \n",
    "# 124000      12.7699     12.7699     0.000289385  334672        \n",
    "# 125000      12.1416     12.1416     0.000286506  337775        \n",
    "# 126000      12.5922     12.5922     0.000283655  340911       \n",
    "#127000       12.6997     12.6997     0.000280833  344026        \n",
    "# 128000      13.0767     13.0767     0.000278038  347111        \n",
    "# 129000      12.0074     12.0074     0.000275272  350268        \n",
    "# 130000      12.1284     12.1284     0.000272533  353354        \n",
    "# 131000      12.4354     12.4354     0.000269821  356466        \n",
    "# 132000      11.7967     11.7967     0.000267136  359618        \n",
    "# 133000      12.3922     12.3922     0.000264478  362748        \n",
    "# 134000      12.0027     12.0027     0.000261847  365844        \n",
    "# 135000      12.2929     12.2929     0.000259241  369025   \n",
    "# 136000      12.0449     12.0449     0.000256662  372200        \n",
    "# 137000      12.106      12.106      0.000254108  375319        \n",
    "# 138000      12.1313     12.1313     0.000251579  378445        \n",
    "# 139000      11.7585     11.7585     0.000249076  381564        \n",
    "# 140000      12.0848     12.0848     0.000246598  384732        \n",
    "# 141000      12.3589     12.3589     0.000244144  387884        \n",
    "# 142000      11.5295     11.5295     0.000241715  390992        \n",
    "# 143000      11.7807     11.7807     0.00023931  394117        \n",
    "# 144000      11.821      11.821      0.000236928  397230        \n",
    "# 145000      11.8141     11.8141     0.000234571  400386        \n",
    "# 146000      11.8843     11.8843     0.000232237  403551        \n",
    "# 147000      11.7224     11.7224     0.000229926  406694        \n",
    "# 148000      11.5571     11.5571     0.000227638  409881        \n",
    "# 149000      12.103      12.103      0.000225373  413025        \n",
    "# 150000      11.5525     11.5525     0.000223131  416148        \n",
    "# 151000      11.5473     11.5473     0.000220911  419306        \n",
    "# 152000      11.2453     11.2453     0.000218712  422418        \n",
    "# 153000      10.951      10.951      0.000216536  425521        \n",
    "# 154000      11.3978     11.3978     0.000214382  428639        \n",
    "# 155000      11.4013     11.4013     0.000212248  431944  \n",
    "# 156000      11.4369     11.4369     0.000210137  435293        \n",
    "# 157000      11.6738     11.6738     0.000208046  438421        \n",
    "# 158000      12.3936     12.3936     0.000205976  441590        \n",
    "# 159000      11.7866     11.7866     0.000203926  444743        \n",
    "# 160000      11.6324     11.6324     0.000201897  447928        \n",
    "# 161000      11.1356     11.1356     0.000199888  451072        \n",
    "# 162000      11.2384     11.2384     0.000197899  454257        \n",
    "# 163000      11.1549     11.1549     0.00019593  457411        \n",
    "# 164000      11.587      11.587      0.00019398  460540        \n",
    "# 165000      11.021      11.021      0.00019205  463740        \n",
    "# 166000      10.8986     10.8986     0.000190139  466931        \n",
    "# 167000      11.691      11.691      0.000188247  470034        \n",
    "# 168000      10.8743     10.8743     0.000186374  473184        \n",
    "# 169000      11.1495     11.1495     0.00018452  476352        \n",
    "# 170000      10.7639     10.7639     0.000182684  479473        \n",
    "# 171000      11.2971     11.2971     0.000180866  482620        \n",
    "# 172000      11.175      11.175      0.000179066  485741        \n",
    "# 173000      10.9317     10.9317     0.000177285  488927        \n",
    "# 174000      10.9018     10.9018     0.000175521  492094        \n",
    "# 175000      10.9454     10.9454     0.000173774  495268        \n",
    "# 176000      11.4809     11.4809     0.000172045  498419        \n",
    "# 177000      10.9679     10.9679     0.000170333  501542        \n",
    "# 178000      11.1397     11.1397     0.000168638  504716        \n",
    "# 179000      10.7722     10.7722     0.00016696  507852        \n",
    "# 180000      11.1619     11.1619     0.000165299  510970        \n",
    "# 181000      11.1312     11.1312     0.000163654  514120        \n",
    "# 182000      11.2299     11.2299     0.000162026  517266        \n",
    "# 183000      10.8833     10.8833     0.000160414  520421        \n",
    "# 184000      10.7197     10.7197     0.000158818  523603        \n",
    "# 185000      11.1702     11.1702     0.000157237  526742        \n",
    "# 186000      10.7632     10.7632     0.000155673  529886        \n",
    "# 187000      10.6083     10.6083     0.000154124  533034        \n",
    "# 188000      10.7333     10.7333     0.00015259  536177        \n",
    "# 189000      10.9713     10.9713     0.000151072  539367        \n",
    "# 190000      10.6769     10.6769     0.000149569  542483  \n",
    "# 191000      10.6101     10.6101     0.00014808  545647        \n",
    "# 192000      10.8125     10.8125     0.000146607  548788        \n",
    "# 193000      10.7871     10.7871     0.000145148  551975        \n",
    "# 194000      10.2772     10.2772     0.000143704  555135        \n",
    "# 195000      10.5243     10.5243     0.000142274  558274        \n",
    "# 196000      10.4488     10.4488     0.000140858  561391        \n",
    "# 197000      10.6396     10.6396     0.000139457  564451        \n",
    "# 198000      10.4315     10.4315     0.000138069  567077        \n",
    "# 199000      11.0021     11.0021     0.000136695  569645        \n",
    "# 200000      10.4966     10.4966     0.000135335  572219        \n",
    "# 201000      10.7146     10.7146     0.000133989  574817        \n",
    "# 202000      10.5162     10.5162     0.000132655  577386        \n",
    "# 203000      10.4969     10.4969     0.000131336  579986        \n",
    "# 204000      10.6306     10.6306     0.000130029  582575        \n",
    "# 205000      10.357      10.357      0.000128735  585183        \n",
    "# 206000      10.3308     10.3308     0.000127454  587766        \n",
    "# 207000      10.2185     10.2185     0.000126186  590348        \n",
    "# 208000      10.2892     10.2892     0.00012493  592931        \n",
    "# 209000      10.3505     10.3505     0.000123687  595534        \n",
    "# 210000      10.1028     10.1028     0.000122456  598151        \n",
    "# 211000      10.2549     10.2549     0.000121238  600746        \n",
    "# 212000      10.3988     10.3988     0.000120032  603322        \n",
    "# 213000      10.4937     10.4937     0.000118837  605857 \n",
    "# 214000      10.4532     10.4532     0.000117655  608398        \n",
    "# 215000      10.5619     10.5619     0.000116484  610969        \n",
    "# 216000      10.0156     10.0156     0.000115325  613551        \n",
    "# 217000      10.0464     10.0464     0.000114178  616326        \n",
    "# 218000      10.6529     10.6529     0.000113041  619344        \n",
    "# 219000      10.0268     10.0268     0.000111917  622351        \n",
    "# 220000      9.98399     9.98399     0.000110803  625478        \n",
    "# 221000      10.2309     10.2309     0.000109701  628513        \n",
    "# 222000      9.85557     9.85557     0.000108609  631587        \n",
    "# 223000      10.2144     10.2144     0.000107528  634659        \n",
    "# 224000      10.3628     10.3628     0.000106458  637672        \n",
    "# 225000      9.93266     9.93266     0.000105399  640727        \n",
    "# 226000      9.84652     9.84652     0.00010435  643872        \n",
    "# 227000      10.3439     10.3439     0.000103312  646982        \n",
    "# 228000      10.1158     10.1158     0.000102284  650123        \n",
    "# 229000      9.86405     9.86405     0.000101266  653255        \n",
    "# 230000      9.98591     9.98591     0.000100259  656425        \n",
    "# 231000      9.89182     9.89182     9.92611e-05  659581        \n",
    "# 232000      10.2688     10.2688     9.82734e-05  662713        \n",
    "# 233000      9.75424     9.75424     9.72956e-05  665828        \n",
    "# 234000      9.94533     9.94533     9.63275e-05  668946        \n",
    "# 235000      10.0589     10.0589     9.5369e-05  672110        \n",
    "# 236000      9.72761     9.72761     9.44201e-05  675280        \n",
    "# 237000      10.1024     10.1024     9.34806e-05  678429        \n",
    "# 238000      9.71764     9.71764     9.25504e-05  681556        \n",
    "# 239000      10.0936     10.0936     9.16295e-05  684722        \n",
    "# 240000      9.90142     9.90142     9.07178e-05  687896        \n",
    "# 241000      10.3031     10.3031     8.98151e-05  691080   \n",
    "# 242000      10.0567     10.0567     8.89214e-05  694276        \n",
    "# 243000      9.51079     9.51079     8.80366e-05  697443        \n",
    "# 244000      9.75928     9.75928     8.71607e-05  700571        \n",
    "# 245000      10.1733     10.1733     8.62934e-05  703706        \n",
    "# 246000      9.8334      9.8334      8.54348e-05  706838        \n",
    "# 247000      9.95693     9.95693     8.45847e-05  710074        \n",
    "# 248000      9.854       9.854       8.3743e-05  713326        \n",
    "# 249000      9.9559      9.9559      8.29098e-05  716469        \n",
    "# 250000      9.69821     9.69821     8.20848e-05  719600        \n",
    "# 251000      10.1917     10.1917     8.1268e-05  722757        \n",
    "# 252000      9.70314     9.70314     8.04594e-05  725916        \n",
    "# 253000      9.75325     9.75325     7.96588e-05  729079        \n",
    "# 254000      9.74271     9.74271     7.88662e-05  732236        \n",
    "# 255000      9.78939     9.78939     7.80815e-05  735374        \n",
    "# 256000      9.40064     9.40064     7.73045e-05  738521        \n",
    "# 257000      9.79821     9.79821     7.65353e-05  741641        \n",
    "# 258000      9.63232     9.63232     7.57738e-05  744778        \n",
    "# 259000      9.88412     9.88412     7.50198e-05  747906        \n",
    "# 260000      9.57372     9.57372     7.42734e-05  751015        \n",
    "# 261000      9.86628     9.86628     7.35343e-05  754114        \n",
    "# 262000      9.68375     9.68375     7.28026e-05  757231        \n",
    "# 263000      9.78728     9.78728     7.20782e-05  760381        \n",
    "# 264000      9.59483     9.59483     7.1361e-05  763538        \n",
    "# 265000      9.32489     9.32489     7.0651e-05  766637        \n",
    "# 266000      9.42444     9.42444     6.9948e-05  769818  \n",
    "# 267000      9.67659     9.67659     6.9252e-05  772966        \n",
    "# 268000      9.60055     9.60055     6.85629e-05  776143        \n",
    "# 269000      9.62905     9.62905     6.78807e-05  779275        \n",
    "# 270000      9.69203     9.69203     6.72053e-05  782426        \n",
    "# 271000      9.60596     9.60596     6.65366e-05  785587  \n",
    "# 272000      9.67285     9.67285     6.58745e-05  788747        \n",
    "# 273000      9.80387     9.80387     6.52191e-05  791872        \n",
    "# 274000      9.37456     9.37456     6.45701e-05  794991        \n",
    "# 275000      9.90353     9.90353     6.39276e-05  798126        \n",
    "# 276000      9.67749     9.67749     6.32915e-05  801298        \n",
    "# 277000      9.69953     9.69953     6.26618e-05  804462        \n",
    "# 278000      9.44851     9.44851     6.20383e-05  807566        \n",
    "# 279000      9.47831     9.47831     6.1421e-05  810656        \n",
    "# 280000      9.69661     9.69661     6.08098e-05  813729        \n",
    "# 281000      9.47622     9.47622     6.02047e-05  816713        \n",
    "# 282000      9.42972     9.42972     5.96057e-05  819671        \n",
    "# 283000      9.13307     9.13307     5.90126e-05  822726        \n",
    "# 284000      9.61275     9.61275     5.84254e-05  825754        \n",
    "# 285000      9.71332     9.71332     5.78441e-05  828774        \n",
    "# 286000      9.40811     9.40811     5.72685e-05  831757        \n",
    "# 287000      9.4811      9.4811      5.66987e-05  834721        \n",
    "# 288000      9.44672     9.44672     5.61345e-05  837692        \n",
    "# 289000      9.6535      9.6535      5.5576e-05  840672        \n",
    "# 290000      9.47068     9.47068     5.5023e-05  843697        \n",
    "# 291000      9.61711     9.61711     5.44755e-05  846734        \n",
    "# 292000      9.23319     9.23319     5.39334e-05  849746        \n",
    "# 293000      9.54719     9.54719     5.33968e-05  852803        \n",
    "# 294000      9.49306     9.49306     5.28655e-05  855774        \n",
    "# 295000      9.54949     9.54949     5.23395e-05  858752        \n",
    "# 296000      9.44547     9.44547     5.18187e-05  861697        \n",
    "# 297000      9.5571      9.5571      5.13031e-05  864717        \n",
    "# 298000      9.12158     9.12158     5.07926e-05  867863        \n",
    "# 299000      9.42967     9.42967     5.02872e-05  870936        \n",
    "# 300000      9.13116     9.13116     4.97868e-05  874007        \n",
    "# 301000      9.33819     9.33819     4.92914e-05  877013        \n",
    "# 302000      9.21345     9.21345     4.8801e-05  879987        \n",
    "# 303000      9.55794     9.55794     4.83154e-05  882954        \n",
    "# 304000      9.75606     9.75606     4.78346e-05  886005        \n",
    "# 305000      9.78506     9.78506     4.73587e-05  888961        \n",
    "# 306000      9.46734     9.46734     4.68874e-05  891936        \n",
    "# 307000      9.34678     9.34678     4.64209e-05  894974        \n",
    "# 308000      9.3525      9.3525      4.5959e-05  898007        \n",
    "# 309000      9.37629     9.37629     4.55017e-05  900980        \n",
    "# 310000      9.13258     9.13258     4.5049e-05  903970        \n",
    "# 311000      9.04357     9.04357     4.46007e-05  907106        \n",
    "# 312000      9.31958     9.31958     4.41569e-05  910189        \n",
    "# 313000      9.28294     9.28294     4.37176e-05  913236        \n",
    "# 314000      9.35659     9.35659     4.32826e-05  916338        \n",
    "# 315000      8.91545     8.91545     4.28519e-05  919481        \n",
    "# 316000      9.30117     9.30117     4.24255e-05  922605        \n",
    "# 317000      9.1749      9.1749      4.20034e-05  925703        \n",
    "# 318000      9.57114     9.57114     4.15854e-05  928784        \n",
    "# 319000      9.27524     9.27524     4.11716e-05  931877        \n",
    "# 320000      9.36833     9.36833     4.0762e-05  934977        \n",
    "# 321000      9.13914     9.13914     4.03564e-05  938147        \n",
    "# 322000      8.99555     8.99555     3.99548e-05  941233        \n",
    "# 323000      9.32532     9.32532     3.95573e-05  944374        \n",
    "# 324000      9.24886     9.24886     3.91637e-05  947492        \n",
    "# 325000      9.1293      9.1293      3.8774e-05  950577        \n",
    "# 326000      8.97721     8.97721     3.83882e-05  953751        \n",
    "# 327000      9.35058     9.35058     3.80062e-05  956899        \n",
    "# 328000      9.37362     9.37362     3.7628e-05  960167        \n",
    "# 329000      9.32745     9.32745     3.72536e-05  963281        \n",
    "# 330000      9.08412     9.08412     3.68829e-05  966418        \n",
    "# 331000      9.31468     9.31468     3.65159e-05  969592        \n",
    "# 332000      9.01207     9.01207     3.61526e-05  972758        \n",
    "# 333000      9.48032     9.48032     3.57929e-05  975847        \n",
    "# 334000      9.14195     9.14195     3.54367e-05  978914        \n",
    "# 335000      9.25655     9.25655     3.50841e-05  982059        \n",
    "# 336000      9.24903     9.24903     3.4735e-05  985184        \n",
    "# 337000      9.29893     9.29893     3.43894e-05  988328        \n",
    "# 338000      9.20102     9.20102     3.40472e-05  991416        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raster 534, pixel 0.25, batch 64, resnet34\n",
    "# 16100 87.364\n",
    "# 31800 67.916\n",
    "# 44000 52.826\n",
    "# 66000 46.433\n",
    "# 85600 37.023\n",
    "# 97000 39.376\n",
    "# 112000 30.721\n",
    "# 126000 29.439\n",
    "# 142k 25.491\n",
    "#154600 25.396\n",
    "#170600 25.682\n",
    "#181700 23.363\n",
    "#198k 23.886\n",
    "#215k 23.295\n",
    "#227k 23.340\n",
    "# 239k 23.719\n",
    "# 246k 23.769\n",
    "# 258k，21.630\n",
    "# 266k, 22.841\n",
    "# 281k, 23.167\n",
    "# 297k 21.912\n",
    "# 314k ,21.564，\n",
    "# 325k，21.623\n",
    "# 338k, 21.622\n",
    "# 342k， 22.135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raster 267, pixel 0.5, batch 64, resnet34\n",
    "# 52k 32.4\n",
    "# 81k 24\n",
    "# 111k 23.9\n",
    "# 146k 23.243\n",
    "# 176k 26.621\n",
    "# 217k 27.006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "from typing import Dict\n",
    "\n",
    "from tempfile import gettempdir\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.resnet import resnet50\n",
    "from tqdm import tqdm\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.dataset import AgentDataset, EgoDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, create_chopped_dataset\n",
    "from l5kit.evaluation.chop_dataset import MIN_FUTURE_STEPS\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from prettytable import PrettyTable\n",
    "from pathlib import Path\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "copying: 100%|██████████| 16220/16220 [04:01<00:00, 67.22it/s]\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/evaluation/extract_ground_truth.py:59: RuntimeWarning:\n",
      "\n",
      "you're running with a custom agents_mask\n",
      "\n",
      "extracting GT: 100%|██████████| 94694/94694 [06:48<00:00, 231.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# ===== GENERATE AND LOAD CHOPPED DATASET\n",
    "num_frames_to_chop = 100\n",
    "eval_cfg = cfg[\"valid_data_loader\"]\n",
    "eval_base_path = create_chopped_dataset(dm.require(eval_cfg[\"key\"]), cfg[\"raster_params\"][\"filter_agents_threshold\"], \n",
    "                              num_frames_to_chop, cfg[\"model_params\"][\"future_num_frames\"], MIN_FUTURE_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   16220    |  1622000   | 125423254  |    11733321   |      45.06      |        100.00        |        77.33         |        10.00         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning:\n",
      "\n",
      "you're running with a custom agents_mask\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_zarr_path = str(Path(eval_base_path) / Path(dm.require(eval_cfg[\"key\"])).name)\n",
    "eval_mask_path = str(Path(eval_base_path) / \"mask.npz\")\n",
    "eval_gt_path = str(Path(eval_base_path) / \"gt.csv\")\n",
    "\n",
    "eval_zarr = ChunkedDataset(eval_zarr_path).open()\n",
    "eval_mask = np.load(eval_mask_path)[\"arr_0\"]\n",
    "# ===== INIT DATASET AND LOAD MASK\n",
    "eval_dataset = AgentDataset(cfg, eval_zarr, rasterizer, agents_mask=eval_mask)\n",
    "eval_dataloader = DataLoader(eval_dataset, shuffle=eval_cfg[\"shuffle\"], batch_size=eval_cfg[\"batch_size\"], \n",
    "                             num_workers=eval_cfg[\"num_workers\"])\n",
    "print(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2960 [00:00<?, ?it/s]/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "/Users/shuozhang/anaconda3/lib/python3.7/site-packages/l5kit/dataset/agent.py:115: RuntimeWarning:\n",
      "\n",
      "disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "\n",
      "100%|██████████| 2960/2960 [3:47:43<00:00,  4.62s/it]  \n"
     ]
    }
   ],
   "source": [
    "timestamps, track_ids, coords, confs = run_prediction(predictor, eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = \"model6_eval5.csv\"\n",
    "write_pred_csv(\n",
    "    eval_path,\n",
    "    timestamps=timestamps,\n",
    "    track_ids=track_ids,\n",
    "    coords=coords,\n",
    "    confs=confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_multi_log_likelihood 29.370679729605982\n",
      "time_displace [0.04612678 0.06858268 0.08922398 0.10907556 0.12888243 0.14844974\n",
      " 0.16786249 0.18659044 0.20341679 0.22138289 0.23912526 0.25730642\n",
      " 0.2747145  0.29207841 0.30954033 0.32557833 0.34012221 0.35381431\n",
      " 0.36744373 0.38052849 0.39259571 0.40478787 0.41634809 0.42728495\n",
      " 0.43907737 0.44852004 0.45847813 0.46798121 0.47859874 0.48711819\n",
      " 0.49692595 0.50606379 0.51587084 0.52436406 0.5348049  0.54402356\n",
      " 0.55409431 0.56561527 0.57459945 0.58619397 0.59838096 0.61004991\n",
      " 0.62327116 0.63740162 0.65243557 0.66863578 0.68587496 0.70347854\n",
      " 0.72369505 0.74385898]\n"
     ]
    }
   ],
   "source": [
    "metrics = compute_metrics_csv(eval_gt_path, eval_path, [neg_multi_log_likelihood, time_displace])\n",
    "for metric_name, metric_mean in metrics.items():\n",
    "    print(metric_name, metric_mean) #170600, 25.682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
